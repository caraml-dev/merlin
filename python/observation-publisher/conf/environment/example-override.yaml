project: "test-project"
model_id: "test-model"
model_version: "0.1.0"
inference_schema:
  # Inference schema associated with the model id and version. For full documentation on the support configuration,
  # refer to the Merlin SDK. Example below is for a binary classification model.

  model_prediction_output:
    output_class: "BinaryClassificationOutput"
    prediction_score_column: "score"
    actual_score_column: "actual_score"
    positive_class_label: "positive"
    negative_class_label: "negative"
    score_threshold: 0.5

  feature_types:
    distance: "int64"
    transaction: "float64"
  prediction_id_column: "prediction_id"
observation_sinks:
  # Supported sink types:
  #  - ARIZE
  #  - BIGQUERY
  - type: "ARIZE"
    config:
      api_key: "SECRET_API_KEY"
      space_key: "SECRET_SPACE_KEY"
  - type: "BIGQUERY"
    config:
      # GCP project for the dataset
      project: "test-project"
      # GCP dataset to store the observation data on
      dataset: "test-dataset"
      # Number of days before the created table will expire
      ttl_days: 14
observation_source:
  # Supported consumer types:
  #  - KAFKA
  type: "KAFKA"
  # (Optional) Number of messages to be kept in-memory before being sent to the sinks. Default: 10
  buffer_capacity: 10
  # (Optional) Maximum duration in seconds to keep messages in-memory before being sent to the sinks, if the capacity is not met. Default: 60
  buffer_max_duration_seconds: 60
  config:
    topic: "test-topic"
    bootstrap_servers: "localhost:9092"
    group_id: "test-group"
    # (Optional) The maximum number of records returned in a single call to poll(). Default: 100
    batch_size: 100
    # (Optional) Additional consumer configuration to be passed to KafkaConsumer.
    additional_consumer_config:
      "auto.offset.reset": "latest"
