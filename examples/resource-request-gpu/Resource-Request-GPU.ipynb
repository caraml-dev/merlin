{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying Resource Request With GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Authenticated to gcloud (```gcloud auth application-default login```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrate how to specify resource request such as CPU, memory, minimum/macimum number of replica, gpu name and gpu count for the model. Without specifying resource request the model will be deployed with system wide defaults. But, one model requires different resource compared to the others and specifying the proper resource will optimize the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin\n",
    "import warnings\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from joblib import dump\n",
    "from sklearn.datasets import load_iris\n",
    "from merlin.model import ModelType\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize MLP Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set MLP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLP Server\n",
    "merlin.set_url(\"localhost:8080/api/merlin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set Active Project\n",
    "\n",
    "`project` represent a project in real life. You may have multiple model within a project.\n",
    "\n",
    "`merlin.set_project(<project_name>)` will set the active project into the name matched by argument. You can only set it to an existing project. If you would like to create a new project, please do so from the MLP console at http://localhost:8080/projects/create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merlin.set_project(\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set Active Model\n",
    "\n",
    "`model` represents an abstract ML model. Conceptually, `model` in MLP is similar to a class in programming language. To instantiate a `model` you'll have to create a `model_version`.\n",
    "\n",
    "Each `model` has a type, currently model type supported by MLP are: sklearn, xgboost, tensorflow, pytorch, and user defined model (i.e. pyfunc model).\n",
    "\n",
    "`model_version` represents a snapshot of particular `model` iteration. You'll be able to attach information such as metrics and tag to a given `model_version` as well as deploy it as a model service.\n",
    "\n",
    "`merlin.set_model(<model_name>, <model_type>)` will set the active model to the name given by parameter, if the model with given name is not found, a new model will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merlin.set_model(\"resource-request\", ModelType.SKLEARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train and Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train and Upload Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`merlin.new_model_version()` is a convenient method to create a model version and start its development process. It is equal to following codes:\n",
    "\n",
    "```\n",
    "v = model.new_model_version()\n",
    "v.start()\n",
    "v.log_model(model_dir=model_dir)\n",
    "v.finish()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"sklearn-model\"\n",
    "MODEL_FILE = \"model.joblib\"\n",
    "\n",
    "url = \"\"\n",
    "\n",
    "# Create new version of the model\n",
    "with merlin.new_model_version() as v:\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    iris = datasets.load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    clf.fit(X, y)\n",
    "    dump(clf, os.path.join(model_dir, MODEL_FILE))\n",
    "    \n",
    "    # Upload the serialized model to MLP\n",
    "    merlin.log_model(model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Deploy Model With Resource Request With GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will specify following resource request for the model which specifies `gpu_request` and `gpu_name` options in addition to previously known options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.resource_request import ResourceRequest\n",
    "\n",
    "resource_req = ResourceRequest(min_replica=0, \n",
    "                               max_replica=2, \n",
    "                               cpu_request=\"1\", \n",
    "                               memory_request=\"1Gi\",\n",
    "                               gpu_request=\"1\",\n",
    "                               gpu_name=\"nvidia-t4\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = merlin.deploy(v, resource_request=resource_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Send Test Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$endpoint.url\"\n",
    "curl -X POST $1 -d '{\n",
    "  \"instances\": [\n",
    "    [2.8,  1.0,  6.8,  0.4],\n",
    "    [3.1,  1.4,  4.5,  1.6]\n",
    "  ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Delete Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "merlin.undeploy(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('merlin-sdk': pipenv)",
   "language": "python",
   "name": "python37064bitmerlinsdkpipenv4227646db3a047c9bf0abdc83ce0196a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
