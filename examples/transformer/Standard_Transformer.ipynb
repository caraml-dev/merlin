{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Transformer Example\n",
    "\n",
    "This notebook demonstrates how to deploy a PyFunc model and a standard transformer. The pyfunc model simply return the request from the transformer. While the transformer itself retrieve the feature from Feast server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Authenticated to gcloud (```gcloud auth application-default login```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Merlin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set Merlin Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin\n",
    "print(merlin.__version__)\n",
    "\n",
    "MERLIN_URL = \"merlin-api-url\"\n",
    "\n",
    "merlin.set_url(MERLIN_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set Active Project\n",
    "\n",
    "`project` represent a project in real life. You may have multiple model within a project.\n",
    "\n",
    "`merlin.set_project(<project-name>)` will set the active project into the name matched by argument. You can only set it to an existing project. If you would like to create a new project, please do so from the MLP UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"sample\"\n",
    "\n",
    "merlin.set_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set Active Model\n",
    "\n",
    "`model` represents an abstract ML model. Conceptually, `model` in Merlin is similar to a class in programming language. To instantiate a `model` you'll have to create a `model_version`.\n",
    "\n",
    "Each `model` has a type, currently model type supported by Merlin are: sklearn, xgboost, tensorflow, pytorch, and user defined model (i.e. pyfunc model).\n",
    "\n",
    "`model_version` represents a snapshot of particular `model` iteration. You'll be able to attach information such as metrics and tag to a given `model_version` as well as deploy it as a model service.\n",
    "\n",
    "`merlin.set_model(<model_name>, <model_type>)` will set the active model to the name given by parameter, if the model with given name is not found, a new model will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.model import ModelType\n",
    "\n",
    "MODEL_NAME = \"pyfunc-standard-transfo\"\n",
    "\n",
    "merlin.set_model(MODEL_NAME, ModelType.PYFUNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create PyFunc Model\n",
    "\n",
    "To create a PyFunc model you'll have to extend `merlin.PyFuncModel` class and implement its `initialize` and `infer` method.\n",
    "\n",
    "`initialize` will be called once during model initialization. The argument to `initialize` is a dictionary containing a key value pair of artifact name and its URL. The artifact's keys are the same value as received by `log_pyfunc_model`.\n",
    "\n",
    "`infer` method is the prediction method that needs to be implemented. It accept a dictionary type argument which represent incoming request body. `infer` should return a dictionary object which correspond to response body of prediction result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In following example we are creating PyFunc model called `StandardModel`. \n",
    "This model will simply echo-ing back the request body to its sender and print `feast_features` that will be populated by standard transformer into stdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from merlin.model import PyFuncModel\n",
    "\n",
    "class StandardModel(PyFuncModel):\n",
    "    def initialize(self, artifacts):\n",
    "        pass\n",
    "        \n",
    "    def infer(self, request, **kwargs):\n",
    "        if \"feast_features\" in request:\n",
    "            logging.info(pd.DataFrame(**request[\"feast_features\"][\"merchant_id\"]))\n",
    "        return request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = StandardModel()\n",
    "m.initialize({})\n",
    "m.infer(\n",
    "    {\n",
    "    \"merchants\": [\n",
    "        {\n",
    "            \"id\" : \"M111\"\n",
    "        },\n",
    "        {\n",
    "            \"id\" : \"M222\"\n",
    "        },\n",
    "        {\n",
    "            \"id\" : \"M333\"\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test whether it could accept feature enrichment from standard transformer. Note that `feast_features` json field will be populated by standard transformer, and the format follow pandas.DataFrame with `split` orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.infer(\n",
    "    {\n",
    "        \"merchants\": [\n",
    "        {\n",
    "            \"id\" : \"M111\"\n",
    "        },\n",
    "        {\n",
    "            \"id\" : \"M222\"\n",
    "        },\n",
    "        {\n",
    "            \"id\" : \"M333\"\n",
    "        }\n",
    "    ], \n",
    "        # feast_features will be populated by standard transformer\n",
    "        \"feast_features\": {\n",
    "          \"merchant_id\" : {\n",
    "            \"columns\": [\n",
    "                \"merchant_id\",\n",
    "                \"merchant_discovery:delivery_time_estimate\"\n",
    "            ],\n",
    "            \"data\": [[\"M111\", 10],[\"M222\", 20],[\"M333\", 30], ]\n",
    "          }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the model, we will have to create an iteration of the model (by create a `model_version`), upload the serialized model to MLP, and then deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create Model Version and Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`merlin.new_model_version()` is a convenient method to create a model version and start its development process. It is equal to following codes:\n",
    "\n",
    "```\n",
    "v = model.new_model_version()\n",
    "v.start()\n",
    "v.log_pyfunc_model(model_instance=EnsembleModel(), \n",
    "                conda_env=\"env.yaml\", \n",
    "                artifacts={\"xgb_model\": model_1_path, \"sklearn_model\": model_2_path})\n",
    "v.finish()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To upload PyFunc model you have to provide following arguments:\n",
    "1. `model_instance` is the instance of PyFunc model, the model has to extend `merlin.PyFuncModel`\n",
    "2. `conda_env` is path to conda environment yaml file. The environment yaml file must contain all dependency required by the PyFunc model.\n",
    "3. (Optional) `artifacts` is additional artifact that you want to include in the model\n",
    "4. (Optional) `code_path` is a list of directory containing python code that will be loaded during model initialization, this is required when `model_instance` depend on local python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with merlin.new_model_version() as v:    \n",
    "    merlin.log_pyfunc_model(model_instance=StandardModel(),\n",
    "                            conda_env=\"standard_transformer_env.yaml\",\n",
    "                            artifacts={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deploy Model and Transformer\n",
    "\n",
    "To deploy a model and its transformer, you must pass a `transformer` object to `deploy()` function. Each of deployed model version will have its own generated url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"standard_transformer_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.resource_request import ResourceRequest\n",
    "from merlin.transformer import StandardTransformer\n",
    "from merlin.logger import Logger, LoggerConfig, LoggerMode\n",
    "\n",
    "# Create a transformer object and its resources requests\n",
    "transformer_config_path = \"standard_transformer_config.yaml\"\n",
    "transformer = StandardTransformer(config_file=transformer_config_path,\n",
    "                                  enabled=True)\n",
    "\n",
    "log = Logger(model=LoggerConfig(enabled=True,  mode=LoggerMode.ALL))\n",
    "endpoint = merlin.deploy(v, transformer=transformer, logger=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Send Test Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "resp = requests.post(endpoint.url, json={\n",
    "    \"merchants\": [\n",
    "        {\n",
    "            \"id\" : \"M111\"\n",
    "        },\n",
    "        {\n",
    "            \"id\" : \"M222\"\n",
    "        },\n",
    "        {\n",
    "            \"id\" : \"M333\"\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    ")\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Delete Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merlin.undeploy(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
