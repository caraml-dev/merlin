{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Standard Transformer Example\n",
    "\n",
    "This notebook demonstrates how to deploy a PyFunc model and a standard transformer. The pyfunc model is an echo model which simply returns the request from the transformer. While the transformer itself has preprocess and postprocess pipeline, including Feast feature retrieval, variable declaration, and table creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "- Authenticated to gcloud (```gcloud auth application-default login```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Initialize Merlin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1 Set Merlin Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import merlin\n",
    "print(merlin.__version__)\n",
    "\n",
    "merlin.set_url(\"https://my-merlin-domain/api/merlin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2 Set Active Project\n",
    "\n",
    "`project` represent a project in real life. You may have multiple model within a project.\n",
    "\n",
    "`merlin.set_project(<project-name>)` will set the active project into the name matched by argument. You can only set it to an existing project. If you would like to create a new project, please do so from the MLP UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"sample\"\n",
    "\n",
    "merlin.set_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.3 Set Active Model\n",
    "\n",
    "`model` represents an abstract ML model. Conceptually, `model` in Merlin is similar to a class in programming language. To instantiate a `model` you'll have to create a `model_version`.\n",
    "\n",
    "Each `model` has a type, currently model type supported by Merlin are: sklearn, xgboost, tensorflow, pytorch, and user defined model (i.e. pyfunc model).\n",
    "\n",
    "`model_version` represents a snapshot of particular `model` iteration. You'll be able to attach information such as metrics and tag to a given `model_version` as well as deploy it as a model service.\n",
    "\n",
    "`merlin.set_model(<model_name>, <model_type>)` will set the active model to the name given by parameter, if the model with given name is not found, a new model will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from merlin.model import ModelType\n",
    "\n",
    "MODEL_NAME = \"transformer-upi\"\n",
    "\n",
    "merlin.set_model(MODEL_NAME, ModelType.PYFUNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Create PyFunc Model\n",
    "\n",
    "To create a PyFunc model you'll have to extend `merlin.PyFuncModel` class and implement its `initialize` and one of `infer` or `upiv1_infer` method.\n",
    "\n",
    "`initialize` will be called once during model initialization. The argument to `initialize` is a dictionary containing a key value pair of artifact name and its URL. The artifact's keys are the same value as received by `log_pyfunc_model`.\n",
    "\n",
    "`infer` method is the prediction method that needs to be implemented when `HTTP_JSON` protocol is used (the default protocol). It accept a dictionary type argument which represent incoming request body. `infer` should return a dictionary object which correspond to response body of prediction result.\n",
    "\n",
    "`upiv1_infer` method is the prediction method that needs to be implemented when `UPI_V1` protocol is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In following example we are creating PyFunc model called `SimpleForwarder` which will simply return back the `prediction_table` field of request as the `prediction_result_table` field of the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import grpc\n",
    "from caraml.upi.utils import df_to_table\n",
    "from caraml.upi.v1 import upi_pb2\n",
    "from caraml.upi.v1 import type_pb2, variable_pb2\n",
    "from merlin.model import PyFuncModel\n",
    "\n",
    "class SimpleForwarder(PyFuncModel):\n",
    "    target_name = \"probability\"\n",
    "    def infer(self, request: dict, **kwargs):\n",
    "        return request\n",
    "\n",
    "    def upiv1_infer(self, request: upi_pb2.PredictValuesRequest,\n",
    "                    context: grpc.ServicerContext) -> upi_pb2.PredictValuesResponse:\n",
    "        return upi_pb2.PredictValuesResponse(prediction_result_table=request.prediction_table, target_name=self.target_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To deploy the model, we will have to create an iteration of the model (by create a `model_version`), upload the serialized model to MLP, and then deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 Create Model Version and Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`merlin.new_model_version()` is a convenient method to create a model version and start its development process. It is equal to following codes:\n",
    "\n",
    "```\n",
    "v = model.new_model_version()\n",
    "v.start()\n",
    "v.log_pyfunc_model(model_instance=EnsembleModel(), \n",
    "                conda_env=\"env.yaml\", \n",
    "                artifacts={\"xgb_model\": model_1_path, \"sklearn_model\": model_2_path})\n",
    "v.finish()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To upload PyFunc model you have to provide following arguments:\n",
    "1. `model_instance` is the instance of PyFunc model, the model has to extend `merlin.PyFuncModel`\n",
    "2. `conda_env` is path to conda environment yaml file. The environment yaml file must contain all dependency required by the PyFunc model.\n",
    "3. (Optional) `artifacts` is additional artifact that you want to include in the model\n",
    "4. (Optional) `code_dir` is a list of directory containing python code that will be loaded during model initialization, this is required when `model_instance` depend on local python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import merlin\n",
    "with merlin.new_model_version() as v:    \n",
    "    merlin.log_pyfunc_model(model_instance=SimpleForwarder(),\n",
    "                            conda_env=\"env.yaml\",\n",
    "                            artifacts={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Deploy Model and Transformer\n",
    "\n",
    "To deploy a model and its transformer, you must pass a `transformer` object to `deploy()` function. Each of deployed model version will have its own generated url. The `transformer` object is initialized by specifying the YAML config file. For specifying Transformer config, refer to [this documention](https://go-jek.atlassian.net/wiki/spaces/DSP/pages/2158857203/Standard+Transformer+Design). You can use merlin UI to easily create the transformer configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!cat \"config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from merlin.transformer import StandardTransformer\n",
    "from merlin.protocol import Protocol\n",
    "\n",
    "\n",
    "# Create a transformer object and its resources requests\n",
    "transformer_config_path = \"config.yaml\"\n",
    "transformer = StandardTransformer(config_file=transformer_config_path,\n",
    "                                  enabled=True)\n",
    "\n",
    "endpoint = merlin.deploy(v, transformer=transformer, protocol=Protocol.UPI_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from caraml.upi.v1 import upi_pb2\n",
    "from typing import List\n",
    "\n",
    "def create_simple_forwarder_request() -> upi_pb2.PredictValuesRequest:\n",
    "    target_name = SimpleForwarder.target_name\n",
    "    cols = [\"id\", \"name\", \"vehicle\", \"previous_vehicle\", \"rating\", \"test_time\", \"row_number\"]\n",
    "    indices = [\"row1\", \"row2\"]\n",
    "    rows = [\n",
    "        [1, \"driver-1\", \"motorcycle\", \"suv\", 4.0, 90, 0],\n",
    "        [2, \"driver-2\", \"sedan\", \"mpv\", 3.0, 90, 1]\n",
    "    ]\n",
    "    driver_df = pd.DataFrame(columns=cols, data=rows, index=indices)\n",
    "    driver_table = df_to_table(driver_df, \"driver_table\")\n",
    "    variables: List[variable_pb2.Variable] = [\n",
    "        variable_pb2.Variable(name=\"customer_id\", type=type_pb2.TYPE_INTEGER, integer_value=1111)\n",
    "    ]\n",
    "    return upi_pb2.PredictValuesRequest(\n",
    "        target_name=target_name,\n",
    "        transformer_input=upi_pb2.TransformerInput(\n",
    "            tables=[driver_table],\n",
    "            variables=variables\n",
    "        )\n",
    "    )\n",
    "\n",
    "def simple_forwarder_response() -> upi_pb2.PredictValuesResponse:\n",
    "    target_name = SimpleForwarder.target_name\n",
    "    cols = [\"customer_id\", \"name\", \"rank\", \"rating\", \"vehicle\", \"previous_vehicle\"]\n",
    "    indices = [\"row2\", \"row1\"]\n",
    "    rows = [\n",
    "        [1111, \"driver-2\", 2.5, 0.5, 2, 3],\n",
    "        [1111, \"driver-1\", -2.5, 0.75, 0, 1]\n",
    "    ]\n",
    "    response_df = pd.DataFrame(columns=cols, data=rows, index=indices)\n",
    "    response_table = df_to_table(response_df, \"transformed_driver_table\")\n",
    "    return upi_pb2.PredictValuesResponse(\n",
    "        target_name=target_name,\n",
    "        prediction_result_table=response_table\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3 Send Test Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import grpc\n",
    "from time import sleep\n",
    "\n",
    "from caraml.upi.v1 import upi_pb2, upi_pb2_grpc\n",
    "\n",
    "channel = grpc.insecure_channel(f\"{endpoint.url}:80\")\n",
    "stub = upi_pb2_grpc.UniversalPredictionServiceStub(channel)\n",
    "\n",
    "print(endpoint.url)\n",
    "sleep(5)\n",
    "\n",
    "request = create_simple_forwarder_request()\n",
    "print(f\"request ---------> {request}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = stub.PredictValues(request=request)\n",
    "print(f\"response ---------> {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1 Delete Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "merlin.undeploy(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
