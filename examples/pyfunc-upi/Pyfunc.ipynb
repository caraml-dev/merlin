{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "- Authenticated to gcloud (```gcloud auth application-default login```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook demonstrate how to develop a python function based model that supports UPI protocol.\n",
    "The model that we are going to develop is a simple iris classifier based on xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -r requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import merlin\n",
    "import warnings\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import uuid\n",
    "from sklearn.datasets import load_iris\n",
    "from merlin.model import ModelType\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize merlin url\n",
    "merlin.set_url(\"https://my-merlin-domain/api/merlin\")\n",
    "# set active project\n",
    "merlin.set_project(\"sample\")\n",
    "# set active model\n",
    "merlin.set_model(\"pyfunc-upi\", ModelType.PYFUNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train iris classifier using sample dataset provided by sklearn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "X = iris['data']\n",
    "\n",
    "param = {\n",
    "            'max_depth': 6,\n",
    "            'eta': 0.1,\n",
    "            'nthread': 4,\n",
    "            'num_class': 3,\n",
    "            'objective': 'multi:softprob'\n",
    "        }\n",
    "\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "xgb_model = xgb.train(params=param, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save the trained model under `./xgboost-model/model.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = \"xgboost-model\"\n",
    "model_filename = \"model.json\"\n",
    "model_path = os.path.join(model_dir, model_filename)\n",
    "xgb_model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Create PyFunc Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To create a PyFunc model you'll have to extend `merlin.PyFuncModel` class and implement its `initialize` and one of `infer` or `upiv1_infer` method.\n",
    "\n",
    "`initialize` will be called once during model initialization. The argument to `initialize` is a dictionary containing a key value pair of artifact name and its URL. The artifact's keys are the same value as received by `log_pyfunc_model`.\n",
    "\n",
    "`infer` method is the prediction method that needs to be implemented when `HTTP_JSON` protocol is used (the default protocol). It accept a dictionary type argument which represent incoming request body. `infer` should return a dictionary object which correspond to response body of prediction result.\n",
    "\n",
    "`upiv1_infer` method is the prediction method that needs to be implemented when `UPI_V1` protocol is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this example, `IrisClassifier` class implements both `infer` and `upiv1_infer` methods which allow the model to be deployed with both `UPI_V1` and `HTTP_JSON` protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from merlin.model import PyFuncModel\n",
    "from merlin.model import PyFuncModel\n",
    "from caraml.upi.utils import df_to_table, table_to_df\n",
    "from caraml.upi.v1 import upi_pb2, upi_pb2_grpc\n",
    "import grpc\n",
    "\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class IrisClassifier(PyFuncModel):\n",
    "    MODEL_ARTIFACT_KEY = \"xgb_model\"\n",
    "\n",
    "    feature_names = [\n",
    "        \"sepal-length\",\n",
    "        \"sepal-width\",\n",
    "        \"petal-length\",\n",
    "        \"petal-width\"\n",
    "    ]\n",
    "\n",
    "    class_names = [\n",
    "        \"setosa\",\n",
    "        \"versicolor\",\n",
    "        \"virginica\"\n",
    "    ]\n",
    "\n",
    "    target_name = \"iris-species\"\n",
    "\n",
    "    def initialize(self, artifacts):\n",
    "        self._model = xgb.Booster(model_file=artifacts[self.MODEL_ARTIFACT_KEY])\n",
    "\n",
    "    def infer(self, request: dict, **kwargs):\n",
    "        \"\"\"\n",
    "        infer is the entry point for HTTP_JSON protocol.\n",
    "        \"\"\"\n",
    "        result = self._predict(request['instances'])\n",
    "        return {\"predictions\": result.to_numpy().tolist()} # not the most efficient\n",
    "\n",
    "    def upiv1_infer(self, request: upi_pb2.PredictValuesRequest,\n",
    "                    context: grpc.ServicerContext) -> upi_pb2.PredictValuesResponse:\n",
    "        \"\"\"\n",
    "        Perform prediction when using UPI_V1 protocol.\n",
    "        The method accept request in form of PredictValuesRequest proto and should return PredictValuesResponse response proto.\n",
    "\n",
    "        :param request: Inference request as PredictValuesRequest\n",
    "        :param context: grpc context\n",
    "        :return: Prediction result as PredictValuesResponse proto\n",
    "        \"\"\"\n",
    "        if not self._validate_request(request, context):\n",
    "            return upi_pb2.PredictValuesResponse()\n",
    "\n",
    "        features_df, _ = table_to_df(request.prediction_table)\n",
    "        prediction_result_df = self._predict(features_df)\n",
    "        return self._create_response(prediction_result_df, request)\n",
    "\n",
    "    def _create_response(self, predictions: pd.DataFrame, request: upi_pb2.PredictValuesRequest) -> upi_pb2.PredictValuesResponse:\n",
    "        \"\"\"\n",
    "        Convert predictions result to upi response ( PredictValuesResponse )\n",
    "\n",
    "        :param predictions: predictions calculated by the model. (pd.DataFrame)\n",
    "        :param request: incoming request (PredictValuesRequest).\n",
    "        :return: PredictValuesResponse\n",
    "        \"\"\"\n",
    "        prediction_result_table = df_to_table(df=predictions, table_name=\"prediction_result\")\n",
    "        response_metadata = upi_pb2.ResponseMetadata(prediction_id=request.metadata.prediction_id,\n",
    "                                                     models=[self._create_model_metadata()])\n",
    "        return upi_pb2.PredictValuesResponse(prediction_result_table=prediction_result_table, target_name=self.target_name, metadata=response_metadata)\n",
    "\n",
    "    def _predict(self, features: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Perform prediction. This shared method that will be called by `infer` and `upiv1_infer`\n",
    "        :param features: features dataframe\n",
    "        :return: prediction result\n",
    "        \"\"\"\n",
    "        features_matrix = xgb.DMatrix(features)\n",
    "        return pd.DataFrame(self._model.predict(features_matrix), columns = self.class_names, dtype=np.float64)\n",
    "\n",
    "    def _create_model_metadata(self):\n",
    "        \"\"\"\n",
    "        create model metadata to be used in response.\n",
    "        \"\"\"\n",
    "        return upi_pb2.ModelMetadata(\n",
    "            name=os.getenv(\"CARAML_MODEL_NAME\", \"iris-classifier\"),\n",
    "            version=os.getenv(\"CARAML_MODEL_VERSION\", \"1\")\n",
    "        )\n",
    "\n",
    "    def _validate_request(self, request: upi_pb2.PredictValuesRequest, context: grpc.ServicerContext):\n",
    "        \"\"\"\n",
    "        Perform request validation\n",
    "\n",
    "        :param request: incoming request\n",
    "        :param context: grpc context\n",
    "\n",
    "        :return: True if request is valid, return False otherwise\n",
    "        \"\"\"\n",
    "        # Check target name matches\n",
    "        if request.target_name != self.target_name:\n",
    "            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)\n",
    "            context.set_details(f\"Invalid target_name, got: {request.target_name}, expected: {self.target_name}\")\n",
    "            return False\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's test `infer` and `upiv1_infer` locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = IrisClassifier()\n",
    "m.initialize({IrisClassifier.MODEL_ARTIFACT_KEY: model_path})\n",
    "m.infer({\"instances\": [[1,2,3,4], [2,1,2,4]] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_upi_request_from_iris_dataset() -> upi_pb2.PredictValuesRequest:\n",
    "    iris_dataset = load_iris()\n",
    "    X = iris_dataset['data']\n",
    "    df = pd.DataFrame(X, columns=IrisClassifier.feature_names)\n",
    "\n",
    "    prediction_table = df_to_table(df, \"prediction_table\")\n",
    "    return upi_pb2.PredictValuesRequest(\n",
    "        target_name=IrisClassifier.target_name,\n",
    "        prediction_table=prediction_table,\n",
    "        metadata=upi_pb2.RequestMetadata(\n",
    "            prediction_id=str(uuid.uuid1())\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m.upiv1_infer(create_upi_request_from_iris_dataset(), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1 Create Model Version and Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with merlin.new_model_version() as v:    \n",
    "    merlin.log_pyfunc_model(model_instance=IrisClassifier(),\n",
    "                            conda_env=\"env.yaml\",\n",
    "                            artifacts={IrisClassifier.MODEL_ARTIFACT_KEY: model_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.2 Deploy Model as UPI Compatible service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Each of a deployed model version will have its own generated url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from merlin.protocol import Protocol\n",
    "\n",
    "endpoint = merlin.deploy(v, protocol = Protocol.UPI_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.3 Send Test Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import grpc\n",
    "\n",
    "channel = grpc.insecure_channel(f\"{endpoint.url}:80\") # Note to add :80 at the end of URL\n",
    "stub = upi_pb2_grpc.UniversalPredictionServiceStub(channel)\n",
    "\n",
    "request = create_upi_request_from_iris_dataset()\n",
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = stub.PredictValues(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.4 Delete Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "merlin.undeploy(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.5 Deploy Model as HTTP service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since the pyfunc model implement `infer` method, it is also possible to deploy the same model using `HTTP_JSON` protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endpoint = merlin.deploy(v) # if protocol is not set, it will default to HTTP_JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Send test request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$endpoint.url\"\n",
    "curl POST $1 -d '{\n",
    "  \"instances\": [\n",
    "    [2.8,  1.0,  6.8,  0.4],\n",
    "    [3.1,  1.4,  4.5,  1.6]\n",
    "  ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.6 Delete Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "merlin.undeploy(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
